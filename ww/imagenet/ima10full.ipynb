{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "modules_dir = 'D:/usr14/project/Binary/adiabaticbinary/ww'\n",
    "sys.path.insert(0, modules_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules import resnet1\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from readdata import read_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=torch.device('cuda')\n",
    "def fit(model:resnet1.ResNet, optim,lossfunc,trainloader: DataLoader):\n",
    "    model.train()\n",
    "    totalloss = 0\n",
    "    for data, target in trainloader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optim.zero_grad()\n",
    "        output = model(data).to(device)\n",
    "        loss = lossfunc(output, target)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        with torch.no_grad():\n",
    "            totalloss += loss.item()*data.size(0)\n",
    "    return totalloss/len(trainloader.sampler)\n",
    "\n",
    "def evaluate(model:resnet1.ResNet, val_loader: DataLoader,lossfunc:nn.CrossEntropyLoss):\n",
    "    model.eval()\n",
    "    loss=0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs).to(device)\n",
    "            loss+=lossfunc(outputs,labels).item()*inputs.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct+=(predicted==labels).sum().item()\n",
    "\n",
    "    return loss/len(val_loader.sampler) ,correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "model = resnet1.ResNet(False, False).to(device)\n",
    "lossfunc=nn.CrossEntropyLoss().to(device)\n",
    "train_loader,val_loader,test_loader=read_dataset(128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, loss: 2.186323071861267, val_loss: 1.7741397729873658, val_acc:0.3373\n",
      "val loss reduced to 1.7741397729873658\n",
      "epoch: 2, loss: 1.6957969888687134, val_loss: 1.5476026124954223, val_acc:0.4195\n",
      "val loss reduced to 1.5476026124954223\n",
      "epoch: 3, loss: 1.5325230318069458, val_loss: 1.374797057914734, val_acc:0.4951\n",
      "val loss reduced to 1.374797057914734\n",
      "epoch: 4, loss: 1.3669288436889648, val_loss: 1.1922884119987487, val_acc:0.5706\n",
      "val loss reduced to 1.1922884119987487\n",
      "epoch: 5, loss: 1.2195643501281739, val_loss: 1.5068196214675904, val_acc:0.5185\n",
      "epoch: 6, loss: 1.1108315605163575, val_loss: 1.0334801809310914, val_acc:0.6392\n",
      "val loss reduced to 1.0334801809310914\n",
      "epoch: 7, loss: 1.0070762053489686, val_loss: 1.0077053094863893, val_acc:0.6573\n",
      "val loss reduced to 1.0077053094863893\n",
      "epoch: 8, loss: 0.9085407932281494, val_loss: 0.8490832136154175, val_acc:0.7015\n",
      "val loss reduced to 0.8490832136154175\n",
      "epoch: 9, loss: 0.8446003293991089, val_loss: 1.1524074582099915, val_acc:0.6232\n",
      "epoch: 10, loss: 0.7903417198181152, val_loss: 0.7371103517532349, val_acc:0.7497\n",
      "val loss reduced to 0.7371103517532349\n",
      "epoch: 11, loss: 0.751474635887146, val_loss: 1.154613557958603, val_acc:0.6417\n",
      "epoch: 12, loss: 0.7272997824668884, val_loss: 0.8551601017951965, val_acc:0.7201\n",
      "epoch: 13, loss: 0.7011126348495483, val_loss: 0.6605906301975251, val_acc:0.7821\n",
      "val loss reduced to 0.6605906301975251\n",
      "epoch: 14, loss: 0.6748136859893799, val_loss: 0.6510728615283966, val_acc:0.7785\n",
      "val loss reduced to 0.6510728615283966\n",
      "epoch: 15, loss: 0.6627489945411682, val_loss: 0.7839259764671326, val_acc:0.7482\n",
      "epoch: 16, loss: 0.6455496401786804, val_loss: 0.7485088000297546, val_acc:0.7511\n",
      "epoch: 17, loss: 0.6346586111068726, val_loss: 0.6611863683700562, val_acc:0.7763\n",
      "epoch: 18, loss: 0.6223077870368957, val_loss: 0.6511970861434937, val_acc:0.7806\n",
      "epoch: 19, loss: 0.6105346354484558, val_loss: 0.5528347757339478, val_acc:0.8094\n",
      "val loss reduced to 0.5528347757339478\n",
      "epoch: 20, loss: 0.6029524856567383, val_loss: 0.5770047246932983, val_acc:0.8044\n",
      "epoch: 21, loss: 0.5929131373405456, val_loss: 0.6954103986740112, val_acc:0.7633\n",
      "epoch: 22, loss: 0.5924897352218628, val_loss: 0.5290115760803222, val_acc:0.8198\n",
      "val loss reduced to 0.5290115760803222\n",
      "epoch: 23, loss: 0.5807419219017029, val_loss: 0.6060156608581543, val_acc:0.8007\n",
      "epoch: 24, loss: 0.5769369429588318, val_loss: 0.5439548415184021, val_acc:0.8182\n",
      "epoch: 25, loss: 0.572885501050949, val_loss: 0.48392989492416383, val_acc:0.8307\n",
      "val loss reduced to 0.48392989492416383\n",
      "epoch: 26, loss: 0.5566078912734985, val_loss: 0.6420113525390625, val_acc:0.7991\n",
      "epoch: 27, loss: 0.5585464667320251, val_loss: 0.5602852465629578, val_acc:0.8115\n",
      "epoch: 28, loss: 0.5598724334716797, val_loss: 0.676846852016449, val_acc:0.7844\n",
      "epoch: 29, loss: 0.5442873733520508, val_loss: 0.5343673624038696, val_acc:0.8121\n",
      "epoch: 30, loss: 0.5447268265724182, val_loss: 0.6580431838989258, val_acc:0.7771\n",
      "epoch: 31, loss: 0.5452894581794738, val_loss: 0.535416588973999, val_acc:0.8225\n",
      "epoch: 32, loss: 0.5369828773498535, val_loss: 0.4502265951156616, val_acc:0.8431\n",
      "val loss reduced to 0.4502265951156616\n",
      "epoch: 33, loss: 0.5358946768760681, val_loss: 0.4470980240345001, val_acc:0.8485\n",
      "val loss reduced to 0.4470980240345001\n",
      "epoch: 34, loss: 0.5317410451889039, val_loss: 0.46971958894729615, val_acc:0.8401\n",
      "epoch: 35, loss: 0.5343165413856507, val_loss: 0.5118511351108551, val_acc:0.8291\n",
      "epoch: 36, loss: 0.5313091932296753, val_loss: 0.4609618658065796, val_acc:0.8472\n",
      "epoch: 37, loss: 0.5174234157562256, val_loss: 0.60146160364151, val_acc:0.799\n",
      "epoch: 38, loss: 0.524200936794281, val_loss: 0.6120038851737976, val_acc:0.8034\n",
      "epoch: 39, loss: 0.517682675075531, val_loss: 0.4979708961486816, val_acc:0.8316\n",
      "epoch: 40, loss: 0.5143948601722718, val_loss: 0.5897180681467056, val_acc:0.8063\n",
      "epoch: 41, loss: 0.5098716666221619, val_loss: 0.620898405456543, val_acc:0.8012\n",
      "epoch: 42, loss: 0.520520850944519, val_loss: 0.5827680721282958, val_acc:0.8174\n",
      "epoch: 43, loss: 0.5117034630775452, val_loss: 0.5540204728126525, val_acc:0.819\n",
      "lr reduced to 0.05\n",
      "epoch: 44, loss: 0.3869331295251846, val_loss: 0.3651638788700104, val_acc:0.8781\n",
      "val loss reduced to 0.3651638788700104\n",
      "epoch: 45, loss: 0.36745809326171874, val_loss: 0.3484300422668457, val_acc:0.8813\n",
      "val loss reduced to 0.3484300422668457\n",
      "epoch: 46, loss: 0.3670267592430115, val_loss: 0.3293322219848633, val_acc:0.8859\n",
      "val loss reduced to 0.3293322219848633\n",
      "epoch: 47, loss: 0.36100224661827085, val_loss: 0.33828853764533995, val_acc:0.892\n",
      "epoch: 48, loss: 0.37483796520233154, val_loss: 0.3949129135131836, val_acc:0.8742\n",
      "epoch: 49, loss: 0.36839607067108154, val_loss: 0.39896676440238954, val_acc:0.8713\n",
      "epoch: 50, loss: 0.3778909914970398, val_loss: 0.46179309720993045, val_acc:0.8474\n",
      "epoch: 51, loss: 0.3766436143875122, val_loss: 0.5059082760810852, val_acc:0.8406\n",
      "epoch: 52, loss: 0.3738589165210724, val_loss: 0.4565008111000061, val_acc:0.8514\n",
      "epoch: 53, loss: 0.37362721219062806, val_loss: 0.5155118015766144, val_acc:0.8364\n",
      "epoch: 54, loss: 0.3770628846645355, val_loss: 0.34448841166496275, val_acc:0.8809\n",
      "epoch: 55, loss: 0.37282446880340575, val_loss: 0.5252282651901246, val_acc:0.8353\n",
      "epoch: 56, loss: 0.37102406587600706, val_loss: 0.35835737257003786, val_acc:0.8776\n",
      "lr reduced to 0.025\n",
      "epoch: 57, loss: 0.2696693293094635, val_loss: 0.22635165487527847, val_acc:0.9254\n",
      "val loss reduced to 0.22635165487527847\n",
      "epoch: 58, loss: 0.25362042665481566, val_loss: 0.2513236777544022, val_acc:0.915\n",
      "epoch: 59, loss: 0.251541800236702, val_loss: 0.27087295541763307, val_acc:0.9106\n",
      "epoch: 60, loss: 0.2437289811372757, val_loss: 0.24878574242591858, val_acc:0.9192\n",
      "epoch: 61, loss: 0.25259451177120207, val_loss: 0.2738520904779434, val_acc:0.9114\n",
      "epoch: 62, loss: 0.2482359129667282, val_loss: 0.2524219916820526, val_acc:0.9159\n",
      "epoch: 63, loss: 0.24895470292568206, val_loss: 0.23282938249707222, val_acc:0.9229\n",
      "epoch: 64, loss: 0.2537207067728043, val_loss: 0.29670276279449465, val_acc:0.9015\n",
      "epoch: 65, loss: 0.25860439825057985, val_loss: 0.2712860682964325, val_acc:0.9101\n",
      "epoch: 66, loss: 0.25148275690078736, val_loss: 0.2865053459882736, val_acc:0.9093\n",
      "epoch: 67, loss: 0.2529330339193344, val_loss: 0.26705967750549314, val_acc:0.9123\n",
      "lr reduced to 0.0125\n",
      "epoch: 68, loss: 0.18739266486167908, val_loss: 0.19655524181127548, val_acc:0.9372\n",
      "val loss reduced to 0.19655524181127548\n",
      "epoch: 69, loss: 0.16937495241165162, val_loss: 0.1988757989883423, val_acc:0.9359\n",
      "epoch: 70, loss: 0.1598126345872879, val_loss: 0.20278064193725587, val_acc:0.9364\n",
      "epoch: 71, loss: 0.16680627781152726, val_loss: 0.20865630158185958, val_acc:0.9318\n",
      "epoch: 72, loss: 0.1631534935593605, val_loss: 0.1945573870934546, val_acc:0.936\n",
      "val loss reduced to 0.1945573870934546\n",
      "epoch: 73, loss: 0.1597275687098503, val_loss: 0.19342305973768234, val_acc:0.9388\n",
      "val loss reduced to 0.19342305973768234\n",
      "epoch: 74, loss: 0.15747602739334107, val_loss: 0.21576254816055299, val_acc:0.93\n",
      "epoch: 75, loss: 0.15944208551645278, val_loss: 0.2089427267357707, val_acc:0.9329\n",
      "epoch: 76, loss: 0.1610001329302788, val_loss: 0.2365725253582001, val_acc:0.9254\n",
      "epoch: 77, loss: 0.15424652346372605, val_loss: 0.24952819237336515, val_acc:0.9247\n",
      "epoch: 78, loss: 0.1542319081068039, val_loss: 0.22568735246658325, val_acc:0.9273\n",
      "epoch: 79, loss: 0.15678918756246565, val_loss: 0.22014743873476983, val_acc:0.9326\n",
      "epoch: 80, loss: 0.1595708426952362, val_loss: 0.2116267601251602, val_acc:0.932\n",
      "epoch: 81, loss: 0.16018501045703887, val_loss: 0.24519859035015107, val_acc:0.9241\n",
      "epoch: 82, loss: 0.15616335856318475, val_loss: 0.22079566804170608, val_acc:0.9305\n",
      "epoch: 83, loss: 0.1583483500480652, val_loss: 0.22763268370628356, val_acc:0.9307\n",
      "lr reduced to 0.00625\n",
      "epoch: 84, loss: 0.1198407144844532, val_loss: 0.18416734793186187, val_acc:0.9443\n",
      "val loss reduced to 0.18416734793186187\n",
      "epoch: 85, loss: 0.10537267971634864, val_loss: 0.1822220184803009, val_acc:0.9451\n",
      "val loss reduced to 0.1822220184803009\n",
      "epoch: 86, loss: 0.09961171860694885, val_loss: 0.17217362344264983, val_acc:0.9462\n",
      "val loss reduced to 0.17217362344264983\n",
      "epoch: 87, loss: 0.09690128054618835, val_loss: 0.18416719570159912, val_acc:0.9454\n",
      "epoch: 88, loss: 0.09765563097000123, val_loss: 0.17911169555187226, val_acc:0.9455\n",
      "epoch: 89, loss: 0.09874904780983924, val_loss: 0.1975756982088089, val_acc:0.9404\n",
      "epoch: 90, loss: 0.09630922160148621, val_loss: 0.19436929874420167, val_acc:0.9411\n",
      "epoch: 91, loss: 0.09629825746417045, val_loss: 0.18788393230438233, val_acc:0.9435\n",
      "epoch: 92, loss: 0.09588812361955643, val_loss: 0.18875576568841934, val_acc:0.9459\n",
      "epoch: 93, loss: 0.09289666531682014, val_loss: 0.19151428839564325, val_acc:0.9438\n",
      "epoch: 94, loss: 0.09542143504023552, val_loss: 0.18480761771202087, val_acc:0.9469\n",
      "epoch: 95, loss: 0.09472025498747826, val_loss: 0.20016397880017758, val_acc:0.9407\n",
      "epoch: 96, loss: 0.09369528646469116, val_loss: 0.2036369082927704, val_acc:0.9401\n",
      "lr reduced to 0.003125\n",
      "epoch: 97, loss: 0.07661638026833534, val_loss: 0.17307896904945375, val_acc:0.9483\n",
      "epoch: 98, loss: 0.06926448087096214, val_loss: 0.1687882044315338, val_acc:0.9511\n",
      "val loss reduced to 0.1687882044315338\n",
      "epoch: 99, loss: 0.06427565812766552, val_loss: 0.1695454737484455, val_acc:0.95\n",
      "epoch: 100, loss: 0.06194623795449734, val_loss: 0.17110390188694, val_acc:0.9485\n",
      "epoch: 101, loss: 0.0642288531243801, val_loss: 0.1691044709086418, val_acc:0.9503\n",
      "epoch: 102, loss: 0.06431527381241321, val_loss: 0.1672590863507241, val_acc:0.95\n",
      "val loss reduced to 0.1672590863507241\n",
      "epoch: 103, loss: 0.06308918180167675, val_loss: 0.17704947695843876, val_acc:0.9487\n",
      "epoch: 104, loss: 0.06182099284529686, val_loss: 0.16872704782485962, val_acc:0.9503\n",
      "epoch: 105, loss: 0.05986280766427517, val_loss: 0.17301778682470323, val_acc:0.9486\n",
      "epoch: 106, loss: 0.06106710072159767, val_loss: 0.17429640474319458, val_acc:0.9495\n",
      "epoch: 107, loss: 0.05800182210803032, val_loss: 0.17988435488343238, val_acc:0.9474\n",
      "epoch: 108, loss: 0.06077864110171795, val_loss: 0.17615516467764974, val_acc:0.9493\n",
      "epoch: 109, loss: 0.059619830378890036, val_loss: 0.17363498221747578, val_acc:0.9487\n",
      "epoch: 110, loss: 0.05710126549899578, val_loss: 0.1787838126897812, val_acc:0.9491\n",
      "epoch: 111, loss: 0.05703861040771008, val_loss: 0.18530743696689606, val_acc:0.9473\n",
      "epoch: 112, loss: 0.056249568122625354, val_loss: 0.17905488522052765, val_acc:0.9498\n",
      "lr reduced to 0.0015625\n",
      "epoch: 113, loss: 0.05126669206917286, val_loss: 0.1738923709154129, val_acc:0.9511\n",
      "epoch: 114, loss: 0.044184644335508345, val_loss: 0.17072101272940635, val_acc:0.95\n",
      "epoch: 115, loss: 0.048737321576476096, val_loss: 0.17165413625240325, val_acc:0.9515\n",
      "epoch: 116, loss: 0.04417224939465523, val_loss: 0.1710598559513688, val_acc:0.9519\n",
      "epoch: 117, loss: 0.04430302301198244, val_loss: 0.17049691870510578, val_acc:0.9499\n",
      "epoch: 118, loss: 0.04260727252215147, val_loss: 0.1725769500686787, val_acc:0.9515\n",
      "epoch: 119, loss: 0.041780451978743076, val_loss: 0.16796874277591706, val_acc:0.9528\n",
      "epoch: 120, loss: 0.04261953083127737, val_loss: 0.1700015182286501, val_acc:0.9536\n",
      "epoch: 121, loss: 0.04147770858258009, val_loss: 0.17066152601242066, val_acc:0.9535\n",
      "epoch: 122, loss: 0.0400831209897995, val_loss: 0.17383133730888367, val_acc:0.9523\n",
      "lr reduced to 0.00078125\n",
      "epoch: 123, loss: 0.03656900857537985, val_loss: 0.1687408349275589, val_acc:0.9532\n",
      "epoch: 124, loss: 0.03801553416252136, val_loss: 0.17055514454841614, val_acc:0.9532\n",
      "epoch: 125, loss: 0.03581147617250681, val_loss: 0.16962416853904724, val_acc:0.9532\n",
      "epoch: 126, loss: 0.036000246961414815, val_loss: 0.17014482698440553, val_acc:0.9533\n",
      "epoch: 127, loss: 0.03510357339680195, val_loss: 0.16976459373235703, val_acc:0.9535\n",
      "epoch: 128, loss: 0.034893722248077394, val_loss: 0.1726362662822008, val_acc:0.9515\n",
      "epoch: 129, loss: 0.0320262925773859, val_loss: 0.16681255922317506, val_acc:0.953\n",
      "val loss reduced to 0.16681255922317506\n",
      "epoch: 130, loss: 0.0319999705478549, val_loss: 0.16662835518717767, val_acc:0.9532\n",
      "val loss reduced to 0.16662835518717767\n",
      "epoch: 131, loss: 0.03188389086052775, val_loss: 0.16523391248062252, val_acc:0.9524\n",
      "val loss reduced to 0.16523391248062252\n",
      "epoch: 132, loss: 0.03194816033616662, val_loss: 0.16860155240297317, val_acc:0.953\n",
      "epoch: 133, loss: 0.03300438220947981, val_loss: 0.17082989186048508, val_acc:0.9532\n",
      "epoch: 134, loss: 0.03408330015093088, val_loss: 0.16951645890027284, val_acc:0.9537\n",
      "epoch: 135, loss: 0.03303648843839765, val_loss: 0.17248629924058914, val_acc:0.9517\n",
      "epoch: 136, loss: 0.03180144869685173, val_loss: 0.175230690073967, val_acc:0.9515\n",
      "epoch: 137, loss: 0.03126866802275181, val_loss: 0.17209557657241822, val_acc:0.9521\n",
      "epoch: 138, loss: 0.03228798404857516, val_loss: 0.17297857737541197, val_acc:0.9508\n",
      "epoch: 139, loss: 0.03316162561252713, val_loss: 0.1707203711643815, val_acc:0.9526\n",
      "epoch: 140, loss: 0.030914301872253417, val_loss: 0.17334461886882782, val_acc:0.9528\n",
      "epoch: 141, loss: 0.03126965478509665, val_loss: 0.17191459538713097, val_acc:0.9518\n",
      "lr reduced to 0.000390625\n",
      "epoch: 142, loss: 0.031427593292295934, val_loss: 0.17083847323656082, val_acc:0.953\n",
      "epoch: 143, loss: 0.030667150256037713, val_loss: 0.17072370653152466, val_acc:0.9529\n",
      "epoch: 144, loss: 0.03081018723100424, val_loss: 0.1696112858772278, val_acc:0.9529\n",
      "epoch: 145, loss: 0.030901429900527, val_loss: 0.17139700670242308, val_acc:0.9532\n",
      "epoch: 146, loss: 0.02943582123965025, val_loss: 0.17215602454543114, val_acc:0.9532\n",
      "epoch: 147, loss: 0.03023806094676256, val_loss: 0.1746187126705423, val_acc:0.9522\n",
      "epoch: 148, loss: 0.028747814838588237, val_loss: 0.17272101079449056, val_acc:0.9526\n",
      "epoch: 149, loss: 0.029928811419010163, val_loss: 0.17250970783233643, val_acc:0.952\n",
      "epoch: 150, loss: 0.029685072891414165, val_loss: 0.17207464124113322, val_acc:0.9533\n"
     ]
    }
   ],
   "source": [
    "lr=0.1\n",
    "counter=0\n",
    "min_val_loss=np.inf\n",
    "for epoch in range(150):\n",
    "    if counter/10==1:\n",
    "        counter=0\n",
    "        lr*=0.5\n",
    "        print(f\"lr reduced to {lr}\")\n",
    "    optim=torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=5e-4)\n",
    "    loss=fit(model,optim,lossfunc,train_loader)\n",
    "    val_loss,val_acc=evaluate(model,val_loader,lossfunc)\n",
    "    print(f'epoch: {epoch+1}, loss: {loss}, val_loss: {val_loss}, val_acc:{val_acc}')\n",
    "    if val_loss<min_val_loss:\n",
    "        min_val_loss=val_loss\n",
    "        print(f\"val loss reduced to {min_val_loss}\")\n",
    "        counter=0\n",
    "        torch.save(model.state_dict(), 'pre1.pth')\n",
    "    else:\n",
    "        counter+=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bry",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
