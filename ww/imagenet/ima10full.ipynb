{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "modules_dir = 'D:/usr14/project/Binary/adiabaticbinary/ww'\n",
    "sys.path.insert(0, modules_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules import resnet1\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from readdata import read_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=torch.device('cuda')\n",
    "def fit(model:resnet1.ResNet, optim,lossfunc,trainloader: DataLoader):\n",
    "    model.train()\n",
    "    totalloss = 0\n",
    "    for data, target in trainloader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optim.zero_grad()\n",
    "        output = model(data).to(device)\n",
    "        loss = lossfunc(output, target)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        with torch.no_grad():\n",
    "            totalloss += loss.item()*data.size(0)\n",
    "    return totalloss/len(trainloader.sampler)\n",
    "\n",
    "def evaluate(model:resnet1.ResNet, val_loader: DataLoader,lossfunc:nn.CrossEntropyLoss):\n",
    "    model.eval()\n",
    "    loss=0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs).to(device)\n",
    "            loss+=lossfunc(outputs,labels).item()*inputs.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct+=(predicted==labels).sum().item()\n",
    "\n",
    "    return loss/len(val_loader.sampler) ,correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet1.ResNet(False, False).to(device)\n",
    "lossfunc=nn.CrossEntropyLoss().to(device)\n",
    "train_loader,val_loader,test_loader=read_dataset(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, loss: 2.212570424079895, val_loss: 1.8024646927760197, val_acc:0.2696153846153846\n",
      "val loss reduced to 1.8024646927760197\n",
      "epoch: 2, loss: 1.7664664088762723, val_loss: 1.72707272199484, val_acc:0.3403846153846154\n",
      "val loss reduced to 1.72707272199484\n",
      "epoch: 3, loss: 1.6745480023897612, val_loss: 1.637961918757512, val_acc:0.39076923076923076\n",
      "val loss reduced to 1.637961918757512\n",
      "epoch: 4, loss: 1.616458020088, val_loss: 1.6346203605945293, val_acc:0.3776923076923077\n",
      "val loss reduced to 1.6346203605945293\n",
      "epoch: 5, loss: 1.5772594547271728, val_loss: 1.5165754674031184, val_acc:0.4123076923076923\n",
      "val loss reduced to 1.5165754674031184\n",
      "epoch: 6, loss: 1.5275495049892327, val_loss: 1.5219117359014658, val_acc:0.4269230769230769\n",
      "epoch: 7, loss: 1.4796075236491668, val_loss: 1.4733678216200607, val_acc:0.4492307692307692\n",
      "val loss reduced to 1.4733678216200607\n",
      "epoch: 8, loss: 1.460910730973268, val_loss: 1.563189444908729, val_acc:0.40615384615384614\n",
      "epoch: 9, loss: 1.4279593257414989, val_loss: 1.4402021011939417, val_acc:0.4307692307692308\n",
      "val loss reduced to 1.4402021011939417\n",
      "epoch: 10, loss: 1.3929707727676783, val_loss: 1.5244993070455697, val_acc:0.4023076923076923\n",
      "epoch: 11, loss: 1.3682913716634115, val_loss: 1.4344434033907376, val_acc:0.46307692307692305\n",
      "val loss reduced to 1.4344434033907376\n",
      "epoch: 12, loss: 1.3594804134124365, val_loss: 1.4685756565974308, val_acc:0.44384615384615383\n",
      "epoch: 13, loss: 1.3311412162047167, val_loss: 1.3405178866019616, val_acc:0.5\n",
      "val loss reduced to 1.3405178866019616\n",
      "epoch: 14, loss: 1.3083079177905352, val_loss: 1.4036000636907724, val_acc:0.48115384615384615\n",
      "epoch: 15, loss: 1.280002678235372, val_loss: 1.264462395447951, val_acc:0.5088461538461538\n",
      "val loss reduced to 1.264462395447951\n",
      "epoch: 16, loss: 1.2731321927828667, val_loss: 1.3613511283581075, val_acc:0.5096153846153846\n",
      "epoch: 17, loss: 1.2211317235995562, val_loss: 1.395943626990685, val_acc:0.47846153846153844\n",
      "epoch: 18, loss: 1.1864750083287556, val_loss: 1.3853392597345207, val_acc:0.4723076923076923\n",
      "epoch: 19, loss: 1.1949873193105063, val_loss: 1.429473375907311, val_acc:0.4707692307692308\n",
      "epoch: 20, loss: 1.1297095269423265, val_loss: 1.1754347828718332, val_acc:0.5584615384615385\n",
      "val loss reduced to 1.1754347828718332\n",
      "epoch: 21, loss: 1.1042378204296797, val_loss: 1.3618446427125197, val_acc:0.5034615384615385\n",
      "epoch: 22, loss: 1.1043238835457043, val_loss: 1.2809530291190514, val_acc:0.525\n",
      "epoch: 23, loss: 1.0844433147479327, val_loss: 1.1708177181390615, val_acc:0.5538461538461539\n",
      "val loss reduced to 1.1708177181390615\n",
      "epoch: 24, loss: 1.0670866804245192, val_loss: 1.324276552933913, val_acc:0.5180769230769231\n",
      "epoch: 25, loss: 1.0329064476795686, val_loss: 1.3114224279843845, val_acc:0.51\n",
      "epoch: 26, loss: 1.0090693910305317, val_loss: 1.9846949540651762, val_acc:0.46384615384615385\n",
      "epoch: 27, loss: 0.9948337469345484, val_loss: 1.3256335940727821, val_acc:0.5388461538461539\n",
      "epoch: 28, loss: 0.9981214419389383, val_loss: 1.3610004447056696, val_acc:0.5046153846153846\n",
      "epoch: 29, loss: 0.9734904118073292, val_loss: 1.077657226048983, val_acc:0.5915384615384616\n",
      "val loss reduced to 1.077657226048983\n",
      "epoch: 30, loss: 0.9501609546098954, val_loss: 1.1659490420268133, val_acc:0.5892307692307692\n",
      "epoch: 31, loss: 0.9504567357821342, val_loss: 1.2406162085899939, val_acc:0.54\n",
      "epoch: 32, loss: 0.9266987075561132, val_loss: 1.212974204650292, val_acc:0.571923076923077\n",
      "epoch: 33, loss: 0.8782209125543252, val_loss: 1.2825685394727266, val_acc:0.558076923076923\n",
      "epoch: 34, loss: 0.898368554910024, val_loss: 1.3988544970292311, val_acc:0.5376923076923077\n",
      "epoch: 35, loss: 0.8512309232124915, val_loss: 1.1716110988763662, val_acc:0.5796153846153846\n",
      "epoch: 36, loss: 0.8319185217221577, val_loss: 1.386152235544645, val_acc:0.5346153846153846\n",
      "epoch: 37, loss: 0.8494125639475308, val_loss: 1.301232738494873, val_acc:0.5353846153846153\n",
      "epoch: 38, loss: 0.8241888048098638, val_loss: 1.0898199184124286, val_acc:0.6223076923076923\n",
      "epoch: 39, loss: 0.7833955638836592, val_loss: 1.446909346947303, val_acc:0.5546153846153846\n",
      "lr reduced to 0.05\n",
      "epoch: 40, loss: 0.627001953125, val_loss: 1.005603587627411, val_acc:0.6403846153846153\n",
      "val loss reduced to 1.005603587627411\n",
      "epoch: 41, loss: 0.5519762721734169, val_loss: 1.395006868655865, val_acc:0.5861538461538461\n",
      "epoch: 42, loss: 0.5398151044356517, val_loss: 1.1178617103283222, val_acc:0.6211538461538462\n",
      "epoch: 43, loss: 0.4998716295376802, val_loss: 1.277829404610854, val_acc:0.6011538461538461\n",
      "epoch: 44, loss: 0.47487749747740915, val_loss: 1.0296330705055823, val_acc:0.6665384615384615\n",
      "epoch: 45, loss: 0.41050495019325844, val_loss: 2.018804556773259, val_acc:0.5380769230769231\n",
      "epoch: 46, loss: 0.4257340486233051, val_loss: 1.1736661272782545, val_acc:0.6626923076923077\n",
      "epoch: 47, loss: 0.38131639242172244, val_loss: 1.5274723030970647, val_acc:0.5788461538461539\n",
      "epoch: 48, loss: 0.3782773346167344, val_loss: 1.5216656978313738, val_acc:0.5923076923076923\n",
      "epoch: 49, loss: 0.30890417371040735, val_loss: 2.2733939596322865, val_acc:0.5019230769230769\n",
      "epoch: 50, loss: 0.29221769351225635, val_loss: 1.5189502382278441, val_acc:0.5765384615384616\n",
      "lr reduced to 0.025\n",
      "epoch: 51, loss: 0.1525871727711115, val_loss: 1.0542387558863713, val_acc:0.686923076923077\n",
      "epoch: 52, loss: 0.07133003785824164, val_loss: 1.0208967445446895, val_acc:0.7092307692307692\n",
      "epoch: 53, loss: 0.04664744679744427, val_loss: 0.9761702908002413, val_acc:0.7042307692307692\n",
      "val loss reduced to 0.9761702908002413\n",
      "epoch: 54, loss: 0.0314024953238475, val_loss: 1.2724629204089826, val_acc:0.6757692307692308\n",
      "epoch: 55, loss: 0.02488836095119134, val_loss: 1.0328327857531034, val_acc:0.7019230769230769\n",
      "epoch: 56, loss: 0.0213735086337114, val_loss: 1.011557305409358, val_acc:0.7111538461538461\n",
      "epoch: 57, loss: 0.019329619196554026, val_loss: 0.9534630964352534, val_acc:0.7169230769230769\n",
      "val loss reduced to 0.9534630964352534\n",
      "epoch: 58, loss: 0.016008884202784453, val_loss: 0.9401755281595083, val_acc:0.72\n",
      "val loss reduced to 0.9401755281595083\n",
      "epoch: 59, loss: 0.012846882530511954, val_loss: 1.0914311027526855, val_acc:0.6896153846153846\n",
      "epoch: 60, loss: 0.011814793350222784, val_loss: 0.9513068775030283, val_acc:0.7203846153846154\n",
      "epoch: 61, loss: 0.01063104058878544, val_loss: 0.9411671642156748, val_acc:0.715\n",
      "epoch: 62, loss: 0.009630349055410195, val_loss: 0.9453652908251836, val_acc:0.7257692307692307\n",
      "epoch: 63, loss: 0.009009288521722341, val_loss: 1.019719398205097, val_acc:0.708076923076923\n",
      "epoch: 64, loss: 0.010293990270927166, val_loss: 0.9717722001442543, val_acc:0.72\n",
      "epoch: 65, loss: 0.008677936053046814, val_loss: 0.9168906729037946, val_acc:0.7280769230769231\n",
      "val loss reduced to 0.9168906729037946\n",
      "epoch: 66, loss: 0.008469861616404393, val_loss: 0.9121945960705097, val_acc:0.7276923076923076\n",
      "val loss reduced to 0.9121945960705097\n",
      "epoch: 67, loss: 0.009146443912043022, val_loss: 0.9281758425785945, val_acc:0.7230769230769231\n",
      "epoch: 68, loss: 0.009006652936148338, val_loss: 1.026525075985835, val_acc:0.7042307692307692\n",
      "epoch: 69, loss: 0.008137633132342345, val_loss: 0.9264466241689828, val_acc:0.7207692307692307\n",
      "epoch: 70, loss: 0.00891661017607802, val_loss: 0.9349401002663832, val_acc:0.7230769230769231\n",
      "epoch: 71, loss: 0.017241537818828454, val_loss: 1.0233816300905667, val_acc:0.6946153846153846\n",
      "epoch: 72, loss: 0.01367373581784658, val_loss: 0.9905511639668392, val_acc:0.6996153846153846\n",
      "epoch: 73, loss: 0.00963573855897173, val_loss: 1.0210573601722717, val_acc:0.7053846153846154\n",
      "epoch: 74, loss: 0.008826324999427948, val_loss: 0.9724237379660973, val_acc:0.7142307692307692\n",
      "epoch: 75, loss: 0.008171967746069033, val_loss: 0.8996783087803767, val_acc:0.7315384615384616\n",
      "val loss reduced to 0.8996783087803767\n",
      "epoch: 76, loss: 0.007379874036384699, val_loss: 0.9249610944894644, val_acc:0.7257692307692307\n",
      "epoch: 77, loss: 0.00722755226234977, val_loss: 0.8821432652840248, val_acc:0.7223076923076923\n",
      "val loss reduced to 0.8821432652840248\n",
      "epoch: 78, loss: 0.007070395970382752, val_loss: 0.9358952980775099, val_acc:0.7180769230769231\n",
      "epoch: 79, loss: 0.007863154826829066, val_loss: 0.9050976357093224, val_acc:0.7288461538461538\n",
      "epoch: 80, loss: 0.007331081203256662, val_loss: 0.8997929719778207, val_acc:0.7230769230769231\n",
      "epoch: 81, loss: 0.00888517699467066, val_loss: 1.0676828567798322, val_acc:0.693076923076923\n",
      "epoch: 82, loss: 0.008181438672905548, val_loss: 0.8854400838338412, val_acc:0.7253846153846154\n",
      "epoch: 83, loss: 0.007231995980135905, val_loss: 0.9194000123097347, val_acc:0.715\n",
      "epoch: 84, loss: 0.007062262951945647, val_loss: 0.9621253582147452, val_acc:0.7076923076923077\n",
      "epoch: 85, loss: 0.007596850975488241, val_loss: 1.0775362289868868, val_acc:0.6907692307692308\n",
      "epoch: 86, loss: 0.3016170480923775, val_loss: 1.808708123427171, val_acc:0.5253846153846153\n",
      "epoch: 87, loss: 0.2911403953112089, val_loss: 2.142497337781466, val_acc:0.4880769230769231\n",
      "lr reduced to 0.0125\n",
      "epoch: 88, loss: 0.09499679585297903, val_loss: 0.9184792624987089, val_acc:0.695\n",
      "epoch: 89, loss: 0.02371948523972279, val_loss: 0.9098153803898738, val_acc:0.7184615384615385\n",
      "epoch: 90, loss: 0.01724114215717866, val_loss: 0.9017930456308219, val_acc:0.7203846153846154\n",
      "epoch: 91, loss: 0.012733793704746626, val_loss: 0.8908315042349009, val_acc:0.7253846153846154\n",
      "epoch: 92, loss: 0.010079332106770613, val_loss: 0.9054852703901438, val_acc:0.72\n",
      "epoch: 93, loss: 0.009302292915108876, val_loss: 0.9330078043387486, val_acc:0.72\n",
      "epoch: 94, loss: 0.008501939128320186, val_loss: 0.908089650961069, val_acc:0.7296153846153847\n",
      "epoch: 95, loss: 0.007335115796289383, val_loss: 0.8944107858951276, val_acc:0.7280769230769231\n",
      "epoch: 96, loss: 0.007749545915195575, val_loss: 0.9011551292125995, val_acc:0.7246153846153847\n",
      "epoch: 97, loss: 0.0075270515262411955, val_loss: 0.8976623914791988, val_acc:0.7215384615384616\n",
      "lr reduced to 0.00625\n",
      "epoch: 98, loss: 0.006323293980258779, val_loss: 0.9015265303391676, val_acc:0.7284615384615385\n",
      "epoch: 99, loss: 0.00611766332306732, val_loss: 0.8849460348716149, val_acc:0.7265384615384616\n",
      "epoch: 100, loss: 0.0057732800351312525, val_loss: 0.8769569490506098, val_acc:0.7315384615384616\n",
      "val loss reduced to 0.8769569490506098\n",
      "epoch: 101, loss: 0.005965909557178234, val_loss: 0.8956745156875023, val_acc:0.73\n",
      "epoch: 102, loss: 0.005707700553660592, val_loss: 0.8813334307303795, val_acc:0.735\n",
      "epoch: 103, loss: 0.0058717337436974045, val_loss: 0.8813749449069683, val_acc:0.7334615384615385\n",
      "epoch: 104, loss: 0.0055719421703654985, val_loss: 0.8795900939061092, val_acc:0.7292307692307692\n",
      "epoch: 105, loss: 0.005875236378170741, val_loss: 0.8789776208767525, val_acc:0.7292307692307692\n",
      "epoch: 106, loss: 0.005441776521933767, val_loss: 0.8804096386982845, val_acc:0.7265384615384616\n",
      "epoch: 107, loss: 0.0057250855908466455, val_loss: 0.8734579192675077, val_acc:0.7261538461538461\n",
      "val loss reduced to 0.8734579192675077\n",
      "epoch: 108, loss: 0.005903555668460635, val_loss: 0.8885789254995493, val_acc:0.73\n",
      "epoch: 109, loss: 0.005059535621832579, val_loss: 0.8838861458118146, val_acc:0.7292307692307692\n",
      "epoch: 110, loss: 0.005846795337274671, val_loss: 0.8865984837825481, val_acc:0.73\n",
      "epoch: 111, loss: 0.004992234498644487, val_loss: 0.8752488191311176, val_acc:0.7319230769230769\n",
      "epoch: 112, loss: 0.005440325340351615, val_loss: 0.8761057131107037, val_acc:0.7338461538461538\n",
      "epoch: 113, loss: 0.005396531230937212, val_loss: 0.9028543835419874, val_acc:0.7338461538461538\n",
      "epoch: 114, loss: 0.0054386807748904595, val_loss: 0.8754900517830482, val_acc:0.7261538461538461\n",
      "epoch: 115, loss: 0.005644781013043263, val_loss: 0.8752665534386268, val_acc:0.7296153846153847\n",
      "epoch: 116, loss: 0.005745818996324371, val_loss: 0.8807750601034898, val_acc:0.7338461538461538\n",
      "epoch: 117, loss: 0.005202289892790409, val_loss: 0.8695964059462914, val_acc:0.7342307692307692\n",
      "val loss reduced to 0.8695964059462914\n",
      "epoch: 118, loss: 0.005332817332102702, val_loss: 0.8827610437686627, val_acc:0.7261538461538461\n",
      "epoch: 119, loss: 0.005510188585433822, val_loss: 0.8763169843416948, val_acc:0.735\n",
      "epoch: 120, loss: 0.005958525798259637, val_loss: 0.8651877957123977, val_acc:0.725\n",
      "val loss reduced to 0.8651877957123977\n",
      "epoch: 121, loss: 0.005087246995132703, val_loss: 0.8844007684634282, val_acc:0.7319230769230769\n",
      "epoch: 122, loss: 0.005172702402163011, val_loss: 0.8681396014873798, val_acc:0.7326923076923076\n",
      "epoch: 123, loss: 0.005541815262956497, val_loss: 0.873221528346722, val_acc:0.7265384615384616\n",
      "epoch: 124, loss: 0.00527105480671311, val_loss: 0.8639030676621657, val_acc:0.735\n",
      "val loss reduced to 0.8639030676621657\n",
      "epoch: 125, loss: 0.00534795423109944, val_loss: 0.8642863788971534, val_acc:0.735\n",
      "epoch: 126, loss: 0.00537098775856579, val_loss: 0.8748787681873028, val_acc:0.7326923076923076\n",
      "epoch: 127, loss: 0.005433103109781559, val_loss: 0.8693245583314162, val_acc:0.7365384615384616\n",
      "epoch: 128, loss: 0.005138015290005849, val_loss: 0.8674970041788541, val_acc:0.7288461538461538\n",
      "epoch: 129, loss: 0.005484545834075946, val_loss: 0.8679424740717961, val_acc:0.7292307692307692\n",
      "epoch: 130, loss: 0.005348682423623709, val_loss: 0.8987339030779325, val_acc:0.7257692307692307\n",
      "epoch: 131, loss: 0.005700362322804255, val_loss: 0.863327476978302, val_acc:0.7276923076923076\n",
      "val loss reduced to 0.863327476978302\n",
      "epoch: 132, loss: 0.005084331581512323, val_loss: 0.8829153277323796, val_acc:0.7315384615384616\n",
      "epoch: 133, loss: 0.0051422130275899786, val_loss: 0.8632095076487615, val_acc:0.7326923076923076\n",
      "val loss reduced to 0.8632095076487615\n",
      "epoch: 134, loss: 0.005142771603348546, val_loss: 0.8823529500227708, val_acc:0.7296153846153847\n",
      "epoch: 135, loss: 0.005131048610768257, val_loss: 0.8626298434917743, val_acc:0.7323076923076923\n",
      "val loss reduced to 0.8626298434917743\n",
      "epoch: 136, loss: 0.00523176999643254, val_loss: 0.8913228918955877, val_acc:0.7292307692307692\n",
      "epoch: 137, loss: 0.005769340211095719, val_loss: 0.8728471583586472, val_acc:0.7307692307692307\n",
      "epoch: 138, loss: 0.005435137899162678, val_loss: 0.8551856305049016, val_acc:0.7357692307692307\n",
      "val loss reduced to 0.8551856305049016\n",
      "epoch: 139, loss: 0.005155441429083928, val_loss: 0.8589621384327228, val_acc:0.7376923076923076\n",
      "epoch: 140, loss: 0.005077860086010052, val_loss: 0.8524112149385306, val_acc:0.7334615384615385\n",
      "val loss reduced to 0.8524112149385306\n",
      "epoch: 141, loss: 0.005073132272809744, val_loss: 0.8652490221537077, val_acc:0.735\n",
      "epoch: 142, loss: 0.005209564068712867, val_loss: 0.8591641653501071, val_acc:0.7369230769230769\n",
      "epoch: 143, loss: 0.0048025171477825215, val_loss: 0.8567615463183477, val_acc:0.7365384615384616\n",
      "epoch: 144, loss: 0.004841708512976765, val_loss: 0.8709173627083118, val_acc:0.7265384615384616\n",
      "epoch: 145, loss: 0.005359982248538962, val_loss: 0.8804116795613216, val_acc:0.7326923076923076\n",
      "epoch: 146, loss: 0.005138688008181559, val_loss: 0.8689761494673215, val_acc:0.7230769230769231\n",
      "epoch: 147, loss: 0.005114097605722073, val_loss: 0.8552086111215444, val_acc:0.7353846153846154\n",
      "epoch: 148, loss: 0.005482937440108985, val_loss: 0.86757411975127, val_acc:0.7288461538461538\n",
      "epoch: 149, loss: 0.005498306670058997, val_loss: 0.8454534750718337, val_acc:0.7315384615384616\n",
      "val loss reduced to 0.8454534750718337\n",
      "epoch: 150, loss: 0.005255446385544462, val_loss: 0.8506187747075008, val_acc:0.7342307692307692\n"
     ]
    }
   ],
   "source": [
    "lr=0.1\n",
    "counter=0\n",
    "min_val_loss=np.inf\n",
    "for epoch in range(150):\n",
    "    if counter/10==1:\n",
    "        counter=0\n",
    "        lr*=0.5\n",
    "        print(f\"lr reduced to {lr}\")\n",
    "    optim=torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=5e-4)\n",
    "    loss=fit(model,optim,lossfunc,train_loader)\n",
    "    val_loss,val_acc=evaluate(model,val_loader,lossfunc)\n",
    "    print(f'epoch: {epoch+1}, loss: {loss}, val_loss: {val_loss}, val_acc:{val_acc}')\n",
    "    if val_loss<min_val_loss:\n",
    "        min_val_loss=val_loss\n",
    "        print(f\"val loss reduced to {min_val_loss}\")\n",
    "        counter=0\n",
    "        torch.save(model.state_dict(), 'pre1.pth')\n",
    "    else:\n",
    "        counter+=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bry",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
